import torch
import numpy as np
from PIL import Image
import os
from typing import List, Tuple, Optional
import math

# ê° íŒ¨í‚¤ì§€ë³„ë¡œ ê°œë³„ ì²´í¬
missing_packages = []
available_packages = []

try:
    from diffusers import DiffusionPipeline, StableDiffusionInpaintPipeline
    available_packages.append("diffusers")
except ImportError:
    missing_packages.append("diffusers")

try:
    import transformers
    available_packages.append("transformers")
except ImportError:
    missing_packages.append("transformers")

try:
    import accelerate
    available_packages.append("accelerate")
except ImportError:
    missing_packages.append("accelerate")

try:
    import xformers
    available_packages.append("xformers")
except ImportError:
    missing_packages.append("xformers")

try:
    import requests
    available_packages.append("requests")
except ImportError:
    missing_packages.append("requests")

# ì˜ì¡´ì„± ìƒíƒœ ì¶œë ¥
if missing_packages:
    print("âŒ Missing packages:")
    for pkg in missing_packages:
        print(f"  - {pkg}")
    print("\nğŸ“¦ To install missing packages:")
    print(f"pip install {' '.join(missing_packages)}")
    
if available_packages:
    print("âœ… Available packages:")
    for pkg in available_packages:
        print(f"  - {pkg}")

DEPENDENCIES_AVAILABLE = len(missing_packages) == 0

class Image2ViewGenerator:
    """
    ê³ í’ˆì§ˆ Novel View Synthesisë¥¼ ìœ„í•œ í´ë˜ìŠ¤
    ìµœì‹  3D-aware ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ë‹¤ì–‘í•œ ì‹œì ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, device: str = "auto"):
        if not DEPENDENCIES_AVAILABLE:
            print(f"\nâŒ Cannot initialize: {len(missing_packages)} packages missing")
            print("Please install the missing packages first:")
            print(f"pip install {' '.join(missing_packages)}")
            raise ImportError(f"Required dependencies not installed: {', '.join(missing_packages)}")
            
        self.device = self._get_device(device)
        self.model = None
        self.is_loaded = False
        
    def _get_device(self, device: str) -> str:
        """ìµœì ì˜ ë””ë°”ì´ìŠ¤ ì„ íƒ"""
        if device == "auto":
            if torch.cuda.is_available():
                return "cuda"
            elif torch.backends.mps.is_available():
                return "mps" 
            else:
                return "cpu"
        return device
    
    def load_model(self):
        """
        ìµœì‹  Novel View Synthesis ëª¨ë¸ ë¡œë”©
        """
        try:
            print(f"Loading advanced view synthesis model on {self.device}...")
            
            # ì—¬ëŸ¬ ëª¨ë¸ì„ ì‹œë„í•´ë³´ê³  ê°€ì¥ ì¢‹ì€ ê²ƒ ì‚¬ìš©
            model_options = [
                # Zero-1-to-3 ê¸°ë°˜ ëª¨ë¸ë“¤
                "lambdalabs/sd-image-variations-diffusers",
                # MVDream ë˜ëŠ” ë‹¤ë¥¸ multi-view ëª¨ë¸
                "ashawkey/mvdream-sd2.1-diffusers",
                # ëŒ€ì•ˆ ëª¨ë¸
                "runwayml/stable-diffusion-v1-5"
            ]
            
            self.model = None
            for model_id in model_options:
                try:
                    print(f"Trying model: {model_id}")
                    self.model = DiffusionPipeline.from_pretrained(
                        model_id,
                        torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                        safety_checker=None,
                        requires_safety_checker=False,
                        use_safetensors=True,
                        variant="fp16" if self.device == "cuda" else None
                    )
                    print(f"Successfully loaded: {model_id}")
                    break
                except Exception as e:
                    print(f"Failed to load {model_id}: {e}")
                    continue
                    
            if self.model is None:
                raise Exception("ëª¨ë“  ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                
            self.model = self.model.to(self.device)
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            if self.device == "cuda":
                try:
                    self.model.enable_memory_efficient_attention()
                except:
                    pass
                try:
                    self.model.enable_xformers_memory_efficient_attention()
                except:
                    pass
                self.model.enable_model_cpu_offload()
                
            self.is_loaded = True
            print("Model loaded and optimized successfully!")
            
        except Exception as e:
            print(f"Error loading model: {e}")
            raise
    
    def generate_multi_view_poses(self, num_views: int = 8) -> List[Tuple[float, float, float]]:
        """
        3D íšŒì „ì„ ìœ„í•œ ì¹´ë©”ë¼ í¬ì¦ˆ ìƒì„± (azimuth, elevation, distance)
        """
        poses = []
        
        # ë” ì²´ê³„ì ì¸ ì¹´ë©”ë¼ ë°°ì¹˜
        azimuth_angles = np.linspace(0, 360, num_views, endpoint=False)
        
        for i, azimuth in enumerate(azimuth_angles):
            # elevationì„ ì¡°ê¸ˆì”© ë³€í™”
            elevation = np.sin(azimuth * np.pi / 180) * 20  # -20 ~ +20ë„ ë²”ìœ„
            distance = 1.5  # ê¸°ë³¸ ê±°ë¦¬
            
            poses.append((azimuth, elevation, distance))
            
        return poses
    
    def create_enhanced_prompt(self, azimuth: float, elevation: float, base_prompt: str = "") -> str:
        """
        ë” ì •í™•í•œ ì‹œì  ì •ë³´ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        """
        # ì •í™•í•œ ë°©í–¥ ì„¤ëª…
        if -22.5 <= azimuth < 22.5 or 337.5 <= azimuth < 360:
            view_desc = "front view"
        elif 22.5 <= azimuth < 67.5:
            view_desc = "front-right view"
        elif 67.5 <= azimuth < 112.5:
            view_desc = "right side view" 
        elif 112.5 <= azimuth < 157.5:
            view_desc = "back-right view"
        elif 157.5 <= azimuth < 202.5:
            view_desc = "back view"
        elif 202.5 <= azimuth < 247.5:
            view_desc = "back-left view"
        elif 247.5 <= azimuth < 292.5:
            view_desc = "left side view"
        else:
            view_desc = "front-left view"
            
        # elevation ì„¤ëª…
        if elevation > 20:
            view_desc += ", high angle view, from above"
        elif elevation > 5:
            view_desc += ", slightly from above"
        elif elevation < -20:
            view_desc += ", low angle view, from below"
        elif elevation < -5:
            view_desc += ", slightly from below"
        else:
            view_desc += ", eye level"
            
        prompt = f"{base_prompt}, {view_desc}, professional photography, high resolution, detailed, well-lit, sharp focus"
        return prompt
    
    def preprocess_image(self, image_path: str, target_size: Tuple[int, int] = (512, 512)) -> Image.Image:
        """
        ë” ë‚˜ì€ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        """
        if isinstance(image_path, str):
            image = Image.open(image_path)
        else:
            image = image_path
            
        # RGBë¡œ ë³€í™˜
        if image.mode != 'RGB':
            image = image.convert('RGB')
            
        # ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì¦ˆ
        original_width, original_height = image.size
        target_width, target_height = target_size
        
        # ë¹„ìœ¨ ê³„ì‚°
        ratio = min(target_width/original_width, target_height/original_height)
        new_width = int(original_width * ratio)
        new_height = int(original_height * ratio)
        
        # ë¦¬ì‚¬ì´ì¦ˆ
        image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # ì¤‘ì•™ì— ë°°ì¹˜í•˜ì—¬ íƒ€ê²Ÿ í¬ê¸°ë¡œ íŒ¨ë”©
        new_image = Image.new('RGB', target_size, (255, 255, 255))
        paste_x = (target_width - new_width) // 2
        paste_y = (target_height - new_height) // 2
        new_image.paste(image, (paste_x, paste_y))
        
        return new_image
    
    def generate_novel_views(
        self, 
        image_path: str, 
        num_views: int = 8,
        output_dir: str = "generated_views",
        base_prompt: str = "a high quality photograph of an object",
        guidance_scale: float = 7.5,
        num_inference_steps: int = 30,
        strength: float = 0.8
    ) -> List[str]:
        """
        ê³ í’ˆì§ˆ Novel View ìƒì„±
        """
        if not self.is_loaded:
            self.load_model()
            
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        input_image = self.preprocess_image(image_path)
        print(f"Processed input image: {input_image.size}")
        
        # ì›ë³¸ ì´ë¯¸ì§€ë„ ì €ì¥
        original_path = os.path.join(output_dir, "00_original.png")
        input_image.save(original_path)
        
        # ì¹´ë©”ë¼ í¬ì¦ˆ ìƒì„±
        camera_poses = self.generate_multi_view_poses(num_views)
        
        generated_paths = [original_path]  # ì›ë³¸ í¬í•¨
        
        print(f"Generating {num_views} novel views...")
        
        for i, (azimuth, elevation, distance) in enumerate(camera_poses):
            print(f"Generating view {i+1}/{num_views} (azimuth: {azimuth:.1f}Â°, elevation: {elevation:.1f}Â°)")
            
            # ì‹œì ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.create_enhanced_prompt(azimuth, elevation, base_prompt)
            print(f"Prompt: {prompt}")
            
            try:
                # ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±
                with torch.autocast(self.device):
                    if hasattr(self.model, 'image_encoder') or 'image-variations' in str(type(self.model)):
                        # Image variation ëª¨ë¸
                        generated_image = self.model(
                            image=input_image,
                            guidance_scale=guidance_scale,
                            num_inference_steps=num_inference_steps,
                            height=512,
                            width=512
                        ).images[0]
                    else:
                        # Text-to-imageë¡œ ì´ë¯¸ì§€ ì¬ìƒì„±
                        generated_image = self.model(
                            prompt=prompt,
                            guidance_scale=guidance_scale,
                            num_inference_steps=num_inference_steps,
                            height=512,
                            width=512
                        ).images[0]
                
                # ê²°ê³¼ ì €ì¥
                output_path = os.path.join(output_dir, f"view_{i+1:02d}_az{azimuth:.0f}_el{elevation:.0f}.png")
                generated_image.save(output_path, quality=95)
                generated_paths.append(output_path)
                
                print(f"âœ“ Saved: {output_path}")
                
            except Exception as e:
                print(f"âœ— Error generating view {i+1}: {e}")
                continue
                
        return generated_paths
    
    def create_video_from_views(self, image_paths: List[str], output_path: str = "novel_views.mp4", fps: int = 3):
        """
        ê³ í’ˆì§ˆ íšŒì „ ë¹„ë””ì˜¤ ìƒì„±
        """
        try:
            import cv2
            
            if len(image_paths) < 2:
                print("Need at least 2 images to create video")
                return
                
            # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¡œ ë¹„ë””ì˜¤ ì„¤ì •
            first_img = cv2.imread(image_paths[0])
            height, width, layers = first_img.shape
            
            # ê³ í’ˆì§ˆ ë¹„ë””ì˜¤ ì„¤ì •
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            # ëª¨ë“  ì´ë¯¸ì§€ ì¶”ê°€ (2ë²ˆì”© ë°˜ë³µí•´ì„œ ë” ë¶€ë“œëŸ½ê²Œ)
            for img_path in image_paths:
                img = cv2.imread(img_path)
                if img is not None:
                    video.write(img)
                    video.write(img)  # ë‘ ë²ˆ ì¶”ê°€
                    
            # ë£¨í”„ë¥¼ ìœ„í•´ ì²« ì´ë¯¸ì§€ ë‹¤ì‹œ ì¶”ê°€
            video.write(first_img)
            
            video.release()
            print(f"âœ“ Video created: {output_path}")
            
        except ImportError:
            print("OpenCV not installed. Install with: pip install opencv-python")
        except Exception as e:
            print(f"Error creating video: {e}")

def check_additional_dependencies():
    """ì¶”ê°€ ì˜ì¡´ì„± ì²´í¬"""
    additional_missing = []
    
    try:
        import cv2
        print("âœ… opencv-python available")
    except ImportError:
        additional_missing.append("opencv-python")
        print("âŒ opencv-python missing (needed for video creation)")
    
    if additional_missing:
        print(f"Optional dependencies missing: {', '.join(additional_missing)}")
        print(f"Install with: pip install {' '.join(additional_missing)}")

def main():
    """ê°œì„ ëœ ì‚¬ìš© ì˜ˆì‹œ"""
    print("ğŸ” Checking dependencies...")
    check_additional_dependencies()
    
    if not DEPENDENCIES_AVAILABLE:
        print(f"\nâŒ Cannot proceed: {len(missing_packages)} required packages missing")
        print("Please install the missing packages first:")
        print(f"pip install {' '.join(missing_packages)}")
        return
    
    img_path = "000000000139.jpg"
    
    if not os.path.exists(img_path):
        print(f"âŒ Image not found: {img_path}")
        print("Please make sure the image file exists in the current directory.")
        return
    
    print("\nğŸš€ Starting High-Quality Novel View Synthesis...")
    print(f"ğŸ“· Input image: {img_path}")
    
    # View generator ì´ˆê¸°í™”
    try:
        generator = Image2ViewGenerator()
    except ImportError as e:
        print(f"âŒ Failed to initialize: {e}")
        return
    
    try:
        # ìƒˆë¡œìš´ ì‹œì ë“¤ ìƒì„±
        generated_paths = generator.generate_novel_views(
            image_path=img_path,
            num_views=8,
            output_dir="novel_views",
            base_prompt="a detailed high quality photograph of the object",
            guidance_scale=7.5,
            num_inference_steps=30
        )
        
        print(f"\nâœ… Generated {len(generated_paths)} images (including original)!")
        print(f"ğŸ“ Output directory: novel_views/")
        
        # ë¹„ë””ì˜¤ ìƒì„±
        if len(generated_paths) > 1:
            generator.create_video_from_views(generated_paths, "rotating_view.mp4", fps=3)
            print(f"ğŸ¬ Video created: rotating_view.mp4")
            
        print("\nğŸ‰ Novel view synthesis completed successfully!")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        print("\nğŸ’¡ Make sure you have installed all required packages:")
        print(f"pip install {' '.join(missing_packages + ['opencv-python'])}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()